{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated by ChatGPT o3-mini-high and modified by kei-mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===========================\n",
    "# 1. ハイパーパラメータの設定\n",
    "# ===========================\n",
    "T = 1.0  # 最大時刻\n",
    "beta = 10.0  # 定数beta（大きくすることでT=1でほぼ完全なノイズ状態に）\n",
    "num_epochs = 10000  # 学習エポック数（デモ用なので少なめに設定してもOK）\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "# α(t)=exp(-beta*t)\n",
    "def alpha_bar(t):\n",
    "    return torch.exp(-beta * t)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# 2. 混合ガウス分布からサンプリングする関数\n",
    "# =========================================\n",
    "def sample_data(batch_size):\n",
    "    # 2成分の混合ガウス：平均[-2,0] と [2,0]、共分散は単位行列\n",
    "    means = [torch.tensor([-2.0, 0.0]), torch.tensor([2.0, 0.0])]\n",
    "    # 各サンプルで成分をランダムに選択\n",
    "    comp = torch.randint(0, 2, (batch_size,))\n",
    "    samples = []\n",
    "    for i in range(batch_size):\n",
    "        mu = means[comp[i]]\n",
    "        samples.append(mu + torch.randn(2))\n",
    "    return torch.stack(samples, dim=0)\n",
    "\n",
    "\n",
    "# ====================================\n",
    "# 3. スコア推定のためのネットワークの定義\n",
    "# ====================================\n",
    "class ScoreNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ScoreNet, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(3, 128),  # 入力：2次元のxとスカラーt\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2),  # 出力：2次元のスコア\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # tが1次元の場合、unsqueezeして結合できるようにする\n",
    "        if t.dim() == 1:\n",
    "            t = t.unsqueeze(1)\n",
    "        inp = torch.cat([x, t], dim=1)\n",
    "        return self.net(inp)\n",
    "\n",
    "\n",
    "# インスタンス生成\n",
    "score_model = ScoreNet()\n",
    "optimizer = optim.Adam(score_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# ===========================\n",
    "# 4. スコアマッチングによる学習ループ\n",
    "# ===========================\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # (1) データ x0 を混合ガウス分布からサンプリング\n",
    "    x0 = sample_data(batch_size)  # shape: [batch_size, 2]\n",
    "\n",
    "    # (2) t を一様に [0, T] からサンプル（各サンプル毎に異なるt）\n",
    "    t = torch.rand(batch_size) * T  # shape: [batch_size]\n",
    "\n",
    "    # (3) α(t) を計算（shapeを合わせるためunsqueeze）\n",
    "    a = alpha_bar(t).unsqueeze(1)  # shape: [batch_size, 1]\n",
    "\n",
    "    # (4) ノイズ ε を標準正規分布からサンプリング\n",
    "    noise = torch.randn_like(x0)\n",
    "\n",
    "    # (5) forward process により x_t を生成\n",
    "    sqrt_a = torch.sqrt(a)\n",
    "    sqrt_one_minus_a = torch.sqrt(1 - a)\n",
    "    x_t = sqrt_a * x0 + sqrt_one_minus_a * noise\n",
    "\n",
    "    # (6) ターゲットスコア： s_target = -ε / sqrt(1 - α(t))\n",
    "    target_score = -noise / sqrt_one_minus_a\n",
    "\n",
    "    # (7) ネットワークによるスコア推定\n",
    "    s_pred = score_model(x_t, t)\n",
    "\n",
    "    # (8) MSE損失の計算\n",
    "    loss = ((s_pred - target_score) ** 2).mean()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}: loss = {loss.item():.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 5. 学習済みスコアを用いた逆SDEによるサンプリング\n",
    "# ===========================================\n",
    "def sample_reverse_sde(x_T, num_steps):\n",
    "    \"\"\"\n",
    "    逆SDEのEuler-Maruyama法によるサンプリング\n",
    "    逆SDE: dx = [ -0.5*beta*x - beta*s_theta(x,t) ] dt + sqrt(beta) dW̄\n",
    "    \"\"\"\n",
    "    dt = T / num_steps\n",
    "    x = x_T\n",
    "    # 初期tはT（各サンプル毎に）\n",
    "    t = T * torch.ones(x_T.size(0))\n",
    "    for i in range(num_steps):\n",
    "        # 逆SDEのドリフト項\n",
    "        drift = -0.5 * beta * x - beta * score_model(x, t)\n",
    "        # ノイズ項\n",
    "        noise = torch.randn_like(x)\n",
    "        x = x + drift * dt + torch.sqrt(torch.tensor(beta * dt)) * noise\n",
    "        t = t - dt  # 時刻を逆行\n",
    "    return x\n",
    "\n",
    "\n",
    "# サンプル生成（num_samples個）\n",
    "num_samples = 1000\n",
    "# 逆SDEの開始点 x_T は、forward process により完全なノイズ状態となるので、標準正規分布からサンプル\n",
    "x_T = torch.randn(num_samples, 2)\n",
    "x_gen = sample_reverse_sde(x_T, num_steps=1000)\n",
    "\n",
    "# ---------------------\n",
    "# 6. 結果の可視化\n",
    "# ---------------------\n",
    "import numpy as np\n",
    "\n",
    "# 生成されたサンプルのプロット\n",
    "x_gen_np = x_gen.detach().numpy()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_gen_np[:, 0], x_gen_np[:, 1], s=10, alpha=0.5)\n",
    "plt.title(\"学習済みスコアによる逆SDEサンプリング結果\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 元のデータ分布も確認\n",
    "x_data = sample_data(1000).detach().numpy()\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_data[:, 0], x_data[:, 1], s=10, alpha=0.5, color=\"red\")\n",
    "plt.title(\"混合ガウス分布からの元データ\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
